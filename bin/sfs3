#!/usr/bin/perl

use strict;
use warnings;
use feature qw( say switch );

use Net::Async::AmazonS3::FSLike;

use IO::Async::Loop;
use IO::Async::Timer::Periodic;

use File::Basename qw( basename );
use Future;
use Getopt::Long;
use POSIX qw( ceil );
use Time::HiRes qw( time );
use YAML qw( LoadFile );

my $config = LoadFile( "etc/sfs3.conf" );

my $loop = IO::Async::Loop->new;
my $s3 = Net::Async::AmazonS3::FSLike->new(
   access_key => $config->{access_key},
   secret_key => $config->{secret_key},
);
$loop->add( $s3 );

sub start_progress
{
   my ( $len_total, $len_so_far_ref ) = @_;

   my $start_time = time;

   my $timer = IO::Async::Timer::Periodic->new(
      on_tick => sub {
         my $now = time;
         my $rate = $$len_so_far_ref / ( $now - $start_time );
         my $eta = ( $len_total - $$len_so_far_ref ) / $rate;

         printf "Done %.2f%% (%d of %d) %.2f KB/sec; ETA %d sec\n",
            100 * $$len_so_far_ref / $len_total, $$len_so_far_ref, $len_total,
            $rate / 1000, ceil( $eta );
      },
      interval => 1,
   );
   $loop->add( $timer->start );
}

## main
given( shift @ARGV ) {
   when( "ls" ) {
      GetOptions(
         'l|long' => \my $LONG,
      );
      my $s3path = shift @ARGV;
      my @content = $s3->list_dir(
         bucket => $config->{bucket},
         path   => $s3path,
      )->get;

      foreach my $e ( @content ) {
         if( $LONG and $e->{type} eq "F" ) {
            printf "%s %-36s %15d %s\n", $e->{type}, $e->{name}, $e->{size}, $e->{last_modified};
         }
         else {
            printf "%s %s\n", $e->{type}, $e->{name};
         }
      }
   }
   when( "cat" ) {
      my $s3path = shift @ARGV;
      $s3->get_file(
         bucket => $config->{bucket},
         path   => $s3path,
         on_chunk => sub {
            my ( $header, $chunk ) = @_;
            print $chunk;
         },
      )->get;
   }
   when( "get" ) {
      my $s3path = shift @ARGV;
      my $localpath = shift @ARGV // $s3path;

      my ( $fh, $len_so_far );
      $s3->get_file(
         bucket => $config->{bucket},
         path   => $s3path,
         on_chunk => sub {
            my ( $header, $chunk ) = @_;

            if( !$fh ) {
               open $fh, ">", $localpath or die "Cannot write $localpath - $!";
               $len_so_far = 0;
               my $len_total = $header->content_length;

               start_progress( $len_total, \$len_so_far );
            }

            $fh->print( $chunk );
            $len_so_far += length $chunk;
         },
      )->get;

      print "Successfully got $s3path to $localpath\n";
   }
   when( "put" ) {
      # TODO: Handle multiparts
      my $localpath = shift @ARGV;
      my $s3path = shift @ARGV;
      $s3path .= basename( $localpath ) if $s3path =~ m{/$};

      open my $fh, "<", $localpath or die "Cannot read $localpath - $!";
      my $len_total = -s $fh;

      die "TODO: Should use multipart upload" if $len_total > 100 * 1024*1024;

      my $len_so_far = 0;

      start_progress( $len_total, \$len_so_far );
      my $result = $s3->put_file(
         bucket => $config->{bucket},
         path   => $s3path,
         content_length => $len_total,
         gen_content => sub {
            return undef if eof $fh;

            my $len = read $fh, my $chunk, 64*1024 or die "Cannot read() - $!";
            $len_so_far += $len;

            return $chunk;
         },
      )->get;

      close $fh;

      print "Successfully put $localpath to $s3path\n";
   }
}
